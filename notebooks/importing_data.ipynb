{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tlc_data(inp_month: str, inp_year: str) -> tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Gets the parquet trip data for Yellow & Green Taxi and For-Hire Vehicles\n",
    "\n",
    "    Params:\n",
    "        url (str): URL containing the data of interest on the [TLC page](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "        month (str): Trip data for a given month\n",
    "        year (str): Trip data for a given year\n",
    "    \n",
    "    Returns:\n",
    "        Numpy arrays in the following order -> Yellow Taxi, Green Taxi, and For-Hire Vehicles\n",
    "    \"\"\"\n",
    "    # Yellow Taxi\n",
    "    url1 = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{inp_year}-{inp_month}.parquet\"\n",
    "    # Green Taxi\n",
    "    url2 = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{inp_year}-{inp_month}.parquet\"\n",
    "    # For-Hire (Uber, Lyft, etc)\n",
    "    url3 = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_{inp_year}-{inp_month}.parquet\"\n",
    "\n",
    "    # Dataframes\n",
    "    df1 = pd.read_parquet(url1, use_threads=False)\n",
    "    df2 = pd.read_parquet(url2, use_threads=False)\n",
    "    df3 = pd.read_parquet(url3, use_threads=False)\n",
    "\n",
    "    # Filter the data to only include records that are in the specific year and month\n",
    "    df1 = df1[(df1[\"tpep_pickup_datetime\"].dt.year == int(inp_year)) & (df1[\"tpep_pickup_datetime\"].dt.month == int(inp_month))]\n",
    "    df2 = df2[(df2[\"lpep_pickup_datetime\"].dt.year == int(inp_year)) & (df2[\"lpep_pickup_datetime\"].dt.month == int(inp_month))]\n",
    "    df3 = df3[(df3[\"pickup_datetime\"].dt.year == int(inp_year)) & (df3[\"pickup_datetime\"].dt.month == int(inp_month))]\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df1.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df2.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df3.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "    # Reset indexes\n",
    "    df1.reset_index(inplace=True)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df3.reset_index(inplace=True)\n",
    "\n",
    "    # Create the folder and then export the data in the 'data' folder\n",
    "    df1_path = f\"data/yellow_tripdata/{inp_year}\"\n",
    "    df2_path = f\"data/green_tripdata/{inp_year}\"\n",
    "    df3_path = f\"data/fhvhv_tripdata/{inp_year}\"\n",
    "    if not os.path.exists(df1_path):\n",
    "        os.makedirs(df1_path)\n",
    "    if not os.path.exists(df2_path):\n",
    "        os.makedirs(df2_path)\n",
    "    if not os.path.exists(df3_path):\n",
    "        os.makedirs(df3_path)\n",
    "    \n",
    "    df1.to_parquet(df1_path + f\"/yellow_tripdata_{inp_year}-{inp_month}.parquet\")\n",
    "    df2.to_parquet(df2_path + f\"/green_tripdata_{inp_year}-{inp_month}.parquet\")\n",
    "    df3.to_parquet(df3_path + f\"/fhvhv_tripdata_{inp_year}-{inp_month}.parquet\")\n",
    "    return df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years: ['2020', '2021', '2022', '2023', '2024']\n",
      "Months: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "# Create a loop and store the data\n",
    "years = [str(year) for year in range(2020, 2025)]\n",
    "months = [\"0\" + str(i) for i in range(1, 10)] + [\"10\", \"11\", \"12\"]\n",
    "\n",
    "print(f\"Years: {years}\")\n",
    "print(f\"Months: {months}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2024 Month: 10\n",
      "Year: 2024 Month: 11\n",
      "Year: 2024 Month: 12\n"
     ]
    }
   ],
   "source": [
    "for inp_year in years:\n",
    "    for inp_month in months:\n",
    "        print(f\"Year: {inp_year} Month: {inp_month}\")\n",
    "        df1, df2, df3 = tlc_data(inp_month=inp_month, inp_year=inp_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-01.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-02.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-03.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-04.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-05.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-06.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-07.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-08.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-09.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-10.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-11.parquet (500000)\n",
      "data/fhvhv_tripdata/2020/fhvhv_tripdata_2020-12.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-01.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-02.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-03.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-04.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-05.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-06.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-07.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-08.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-09.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-10.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-11.parquet (500000)\n",
      "data/fhvhv_tripdata/2021/fhvhv_tripdata_2021-12.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-01.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-02.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-03.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-04.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-05.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-06.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-07.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-08.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-09.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-10.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-11.parquet (500000)\n",
      "data/fhvhv_tripdata/2022/fhvhv_tripdata_2022-12.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-01.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-02.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-03.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-04.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-05.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-06.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-07.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-08.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-09.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-10.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-11.parquet (500000)\n",
      "data/fhvhv_tripdata/2023/fhvhv_tripdata_2023-12.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-01.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-02.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-03.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-04.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-05.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-06.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-07.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-08.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-09.parquet (500000)\n",
      "data/fhvhv_tripdata/2024/fhvhv_tripdata_2024-10.parquet (500000)\n",
      "Total rows: 29000000\n"
     ]
    }
   ],
   "source": [
    "# Get samples from all of the parquet files\n",
    "max_num = 500_000\n",
    "tlc_type = \"fhvhv\"\n",
    "parquet_list = []\n",
    "for year in years:\n",
    "    parquets = os.listdir(f\"data/{tlc_type}_tripdata/{year}/\")\n",
    "    for parquet in parquets:\n",
    "        parquet_path = os.path.join(f\"data/{tlc_type}_tripdata/{year}/\", parquet)\n",
    "        df = pd.read_parquet(parquet_path).drop(columns=\"index\")\n",
    "        max_num = min(max_num, len(df)) # Change this back to min\n",
    "        sample_array = df.sample(n=max_num, replace=False).to_numpy()\n",
    "        parquet_list.append(sample_array)\n",
    "        print(f\"{parquet_path} ({len(parquet_list[-1])})\")\n",
    "\n",
    "# Concatenate all data at once\n",
    "parquet_array = np.concatenate(parquet_list, axis=0)\n",
    "print(f\"Total rows: {len(parquet_array)}\")\n",
    "sample_data = pd.DataFrame(parquet_array, columns=df.columns.str.lower())\n",
    "sample_data.to_csv(f\"data/{tlc_type}_td.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc_tlc_trip_data-YW8OLSCx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
